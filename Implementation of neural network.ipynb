{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN17c6+pFbLsVUCg2eddMfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhdykz/mhdykz-Implementation-of-neural-network/blob/main/Implementation%20of%20neural%20network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gCCgNSG82mmw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'titanic.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "print(\"Train Data Info:\")\n",
        "print(data.info())\n",
        "print(\"\\nTrain Data Sample:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOWMyZx03LZo",
        "outputId": "1d628078-3244-49f5-b75e-e376a80fc562"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Train Data Sample:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for missing datas\n",
        "print(\"Missing values in each column:\")\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtgpiJfW32J6",
        "outputId": "85fe1775-e1d1-4073-f4a6-62b434590c6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filling missing values ​​of 'Age' column with mean\n",
        "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
        "\n",
        "# Remove rows with many missing values\n",
        "data.drop(columns=['Cabin'], inplace=True)\n",
        "\n",
        "# Filling the 'Embarked' column with the mode\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "print(\"\\nData after handling missing values:\")\n",
        "print(data.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOh3kHXk5Yv2",
        "outputId": "bd09bedc-24f4-4da0-9d59-3f5c3aa5e2cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after handling missing values:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "دلیل اصلی نرمال‌سازی:\n",
        "تفاوت در مقیاس ویژگی‌ها: داده‌های مختلف ممکن است مقادیر بسیار متفاوتی داشته باشند. مثلاً ستون Age (سن) می‌تواند مقادیری بین 0 تا 80 داشته باشد، در حالی که ستون Fare (هزینه بلیت) ممکن است مقادیری بین 0 تا چند صد داشته باشد. این تفاوت در مقیاس می‌تواند باعث شود که مدل به ویژگی‌هایی با مقیاس بزرگ‌تر حساس‌تر شود و ویژگی‌های کوچک‌تر را نادیده بگیرد.\n",
        "\n",
        "تسریع در همگرایی مدل: زمانی که ویژگی‌ها در مقیاس مشابهی قرار بگیرند، الگوریتم‌های بهینه‌سازی (مثل نزول گرادیان) سریع‌تر و با کارایی بهتری عمل می‌کنند. اگر مقیاس ویژگی‌ها متفاوت باشد، مدل ممکن است نیاز به تعداد بیشتری از گام‌های بهینه‌سازی داشته باشد تا به یک نتیجه خوب برسد.\n",
        "\n",
        "پیش‌فرض بسیاری از الگوریتم‌ها: بسیاری از الگوریتم‌های یادگیری ماشین فرض می‌کنند که داده‌ها دارای توزیعی نرمال هستند (میانگین 0 و واریانس 1). استانداردسازی به تنظیم داده‌ها در این توزیع کمک می‌کند.\n",
        "\n",
        "نرمال‌سازی چگونه انجام می‌شود؟\n",
        "در اینجا از استانداردسازی استفاده می‌کنیم، به این معنی که هر ویژگی به‌گونه‌ای تغییر می‌کند که دارای میانگین صفر و انحراف معیار یک باشد."
      ],
      "metadata": {
        "id": "1ooL_CjV77Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"\\n'Age' and 'Fare':\")\n",
        "print(data[['Age', 'Fare']].head())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data[['Age', 'Fare']] = scaler.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "print(\"\\nNormalized 'Age' and 'Fare':\")\n",
        "print(data[['Age', 'Fare']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo1kig6-6HNC",
        "outputId": "c2378a4f-4d25-4917-cded-aee5f8bd7b47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'Age' and 'Fare':\n",
            "    Age     Fare\n",
            "0  22.0   7.2500\n",
            "1  38.0  71.2833\n",
            "2  26.0   7.9250\n",
            "3  35.0  53.1000\n",
            "4  35.0   8.0500\n",
            "\n",
            "Normalized 'Age' and 'Fare':\n",
            "        Age      Fare\n",
            "0 -0.592481 -0.502445\n",
            "1  0.638789  0.786845\n",
            "2 -0.284663 -0.488854\n",
            "3  0.407926  0.420730\n",
            "4  0.407926 -0.486337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert properties to numeric values\n",
        "\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)\n",
        "\n",
        "print(\"\\nData after encoding categorical features:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoG7ccRR8NKF",
        "outputId": "36f3ed9a-de78-46c1-c726-54df6dad7c37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after encoding categorical features:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex       Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    0 -0.592481      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  0.638789      1   \n",
            "2                             Heikkinen, Miss. Laina    1 -0.284663      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  0.407926      1   \n",
            "4                           Allen, Mr. William Henry    0  0.407926      0   \n",
            "\n",
            "   Parch            Ticket      Fare  Embarked_Q  Embarked_S  \n",
            "0      0         A/5 21171 -0.502445       False        True  \n",
            "1      0          PC 17599  0.786845       False       False  \n",
            "2      0  STON/O2. 3101282 -0.488854       False        True  \n",
            "3      0            113803  0.420730       False        True  \n",
            "4      0            373450 -0.486337       False        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، داده‌های آموزشی را به دو بخش ویژگی‌ها (Feature Matrix) و برچسب‌ها (Labels) تقسیم می‌کنیم. این کار به این دلیل انجام می‌شود که در الگوریتم‌های یادگیری ماشین، مدل از ویژگی‌ها برای یادگیری استفاده می‌کند و سپس برچسب‌ها را به عنوان خروجی پیش‌بینی می‌کند.\n",
        "\n",
        "جزئیات این مرحله:\n",
        "ویژگی‌ها (Xtrain):\n",
        "\n",
        "ویژگی‌ها همان فاکتورهایی هستند که مدل از آن‌ها برای پیش‌بینی استفاده می‌کند. در مسئله Titanic، این ویژگی‌ها می‌توانند مواردی مثل کلاس بلیت (Pclass)، جنسیت (Sex)، سن (Age)، تعداد اعضای خانواده همراه (SibSp و Parch) و سایر ویژگی‌ها باشند.\n",
        "هر کدام از این ستون‌ها به عنوان یک ورودی برای مدل استفاده می‌شود تا براساس این ویژگی‌ها پیش‌بینی کند که آیا یک مسافر زنده مانده یا نه.\n",
        "در این مرحله، ما چند ویژگی مهم را انتخاب کرده‌ایم تا به عنوان ورودی مدل استفاده شوند:\n",
        "Pclass: کلاس بلیت (1، 2 یا 3)\n",
        "Sex: جنسیت (0 برای مرد، 1 برای زن)\n",
        "Age: سن مسافر\n",
        "SibSp: تعداد اعضای خانواده همراه (خواهر و برادر، همسر)\n",
        "Parch: تعداد والدین یا فرزندان همراه\n",
        "Fare: هزینه بلیت\n",
        "Embarked_Q و Embarked_S: مبدا سفر (بندرهایی که مسافر سوار شده است)\n",
        "برچسب‌ها (Ytrain):\n",
        "\n",
        "برچسب‌ها مقادیری هستند که مدل باید آن‌ها را پیش‌بینی کند. در اینجا، برچسب‌ها همان Survived هستند که مشخص می‌کند آیا مسافر زنده مانده است یا نه. این ستون شامل مقادیر 0 (زنده نمانده) و 1 (زنده مانده) است.\n",
        "مدل با استفاده از ویژگی‌ها سعی می‌کند برچسب درست را پیش‌بینی کند."
      ],
      "metadata": {
        "id": "h6sFLnGT9w0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selection of input properties\n",
        "\n",
        "Xtrain = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']]\n",
        "\n",
        "# Output tags (Survived)\n",
        "\n",
        "Ytrain = data['Survived']\n",
        "\n",
        "print(\"\\nFeature Matrix (Xtrain):\")\n",
        "print(Xtrain.head())\n",
        "print(\"\\nLabels (Ytrain):\")\n",
        "print(Ytrain.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyn2rEhY83c1",
        "outputId": "c42b74c3-b643-4bec-a4cf-ed63b5e7165b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Matrix (Xtrain):\n",
            "   Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_Q  Embarked_S\n",
            "0       3    0 -0.592481      1      0 -0.502445       False        True\n",
            "1       1    1  0.638789      1      0  0.786845       False       False\n",
            "2       3    1 -0.284663      0      0 -0.488854       False        True\n",
            "3       1    1  0.407926      1      0  0.420730       False        True\n",
            "4       3    0  0.407926      0      0 -0.486337       False        True\n",
            "\n",
            "Labels (Ytrain):\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Survived, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، برای شروع آموزش شبکه عصبی، باید وزن‌ها و بایاس‌ها را مقداردهی اولیه کنیم. شبکه‌های عصبی برای یادگیری، به وزن‌ها و بایاس‌ها در لایه‌های مختلف نیاز دارند. این وزن‌ها و بایاس‌ها در ابتدا به صورت تصادفی مقداردهی می‌شوند و سپس در طول فرآیند آموزش با استفاده از پس‌انتشار خطا (Backpropagation) و نزول گرادیان (Gradient Descent) به‌روزرسانی می‌شوند.\n",
        "\n",
        "مفاهیم کلیدی:\n",
        "وزن‌ها (Weights):\n",
        "\n",
        "وزن‌ها مشخص می‌کنند که چقدر یک ویژگی ورودی یا خروجی یک نورون بر نورون‌های بعدی تأثیر می‌گذارد. به عبارت دیگر، وزن‌ها مشخص می‌کنند که هر ورودی چه میزان اهمیت دارد.\n",
        "در شبکه عصبی، هر اتصال بین دو نورون دارای یک وزن است.\n",
        "بایاس‌ها (Biases):\n",
        "\n",
        "بایاس‌ها به مدل کمک می‌کنند تا بتواند در صورت نیاز، شیب تابع فعال‌سازی را تغییر دهد و از صرفاً یک خط مستقیم جلوگیری کند. این باعث انعطاف‌پذیری بیشتر مدل در یادگیری الگوهای پیچیده می‌شود.\n",
        "بایاس‌ها معمولاً به عنوان یک عدد اضافه می‌شوند تا مدل بتواند به راحتی مقادیر خروجی را تغییر دهد.\n",
        "معماری شبکه:\n",
        "ما در اینجا یک شبکه عصبی با یک لایه پنهان و یک لایه خروجی داریم:\n",
        "\n",
        "لایه ورودی: شامل تعداد ویژگی‌های ورودی است که از دیتاست می‌آیند. برای مثال، ما 8 ویژگی داریم (مثل Age، Fare و غیره).\n",
        "لایه پنهان: شامل نورون‌هایی است که بین ورودی و خروجی قرار دارند. در اینجا ما 4 نورون در لایه پنهان داریم.\n",
        "لایه خروجی: شامل یک نورون است که نتیجه نهایی (پیش‌بینی زنده ماندن یا نه) را می‌دهد. چون این یک مسئله دسته‌بندی دو مقداری است (زنده ماندن یا نماندن)، تنها یک نورون در لایه خروجی داریم.\n",
        "جزئیات کد:\n",
        "تعداد نورون‌ها در لایه‌های مختلف:\n",
        "\n",
        "input_size: تعداد ویژگی‌ها در ورودی (در اینجا 8 ویژگی است).\n",
        "hidden_size: تعداد نورون‌ها در لایه پنهان (در اینجا 4 نورون در لایه پنهان انتخاب کرده‌ایم).\n",
        "output_size: تعداد نورون‌ها در لایه خروجی (در اینجا 1، زیرا خروجی ما تنها می‌گوید آیا مسافر زنده مانده یا نه).\n",
        "مقداردهی اولیه وزن‌ها:\n",
        "\n",
        "وزن‌های بین لایه ورودی و پنهان (W1) به صورت تصادفی با استفاده از تابع np.random.randn مقداردهی می‌شوند. این مقادیر تصادفی کوچک به مدل کمک می‌کنند که از یک شروع کاملاً متقارن جلوگیری شود.\n",
        "به همین شکل، وزن‌های بین لایه پنهان و لایه خروجی (W2) نیز به صورت تصادفی مقداردهی می‌شوند.\n",
        "مقداردهی اولیه بایاس‌ها:\n",
        "\n",
        "بایاس‌های هر لایه (b1 و b2) در ابتدا به صورت صفر مقداردهی شده‌اند. این مقادیر در طول آموزش به‌روزرسانی خواهند شد."
      ],
      "metadata": {
        "id": "ALsDNNg-ADxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Number of neurons in different layers\n",
        "input_size = Xtrain.shape[1]  # Number of input features\n",
        "hidden_size = 4  # The number of neurons in the hidden layer\n",
        "output_size = 1  # Number of neurons in the output layer (binary prediction: live/dead)\n",
        "\n",
        "# Initialize weights and biases randomly\n",
        "np.random.seed(42) # For reproducibility of results\n",
        "W1 = np.random.randn(input_size, hidden_size) * 0.01  # Weights between input and hidden layer\n",
        "b1 = np.zeros((1, hidden_size))  # Biases of hidden layer\n",
        "W2 = np.random.randn(hidden_size, output_size) * 0.01  # Weights between output and hidden layer\n",
        "b2 = np.zeros((1, output_size))  # Biases of output layer\n",
        "\n",
        "print(\"\\nInitialized weights and biases:\")\n",
        "print(\"W1:\", W1)\n",
        "print(\"b1:\", b1)\n",
        "print(\"W2:\", W2)\n",
        "print(\"b2:\", b2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frD9DW-g91Ne",
        "outputId": "e0f6e409-c1bf-4f81-8ff9-ba5551b87d20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initialized weights and biases:\n",
            "W1: [[ 0.00496714 -0.00138264  0.00647689  0.0152303 ]\n",
            " [-0.00234153 -0.00234137  0.01579213  0.00767435]\n",
            " [-0.00469474  0.0054256  -0.00463418 -0.0046573 ]\n",
            " [ 0.00241962 -0.0191328  -0.01724918 -0.00562288]\n",
            " [-0.01012831  0.00314247 -0.00908024 -0.01412304]\n",
            " [ 0.01465649 -0.00225776  0.00067528 -0.01424748]\n",
            " [-0.00544383  0.00110923 -0.01150994  0.00375698]\n",
            " [-0.00600639 -0.00291694 -0.00601707  0.01852278]]\n",
            "b1: [[0. 0. 0. 0.]]\n",
            "W2: [[-0.00013497]\n",
            " [-0.01057711]\n",
            " [ 0.00822545]\n",
            " [-0.01220844]]\n",
            "b2: [[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، یک تابع برای عبور رو به جلو ایجاد می‌کنیم که با استفاده از ورودی‌ها، خروجی هر لایه را محاسبه می‌کند. این تابع از فرمول‌هایی که قبلاً در تحقیق قبل بیان کردیم استفاده می‌کند."
      ],
      "metadata": {
        "id": "WqD36iMvGezk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def forward_pass(X, W1, b1, W2, b2):\n",
        "    \"\"\"\n",
        "    Implementation of forward pass of neural network\n",
        "    X: input data\n",
        "    W1, b1: hidden layer weights and biases\n",
        "    W2, b2: weights and biases of the output layer\n",
        "    Returns: final output (y_hat) and intermediate values ​​(z1, a1)\n",
        "    \"\"\"\n",
        "    # calculate z1 (input to the hidden layer)\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "\n",
        "    # calculate a1 (hidden layer output with hyperbolic tangent function)\n",
        "    a1 = np.tanh(z1)\n",
        "\n",
        "    # calculate z2 (input to output layer)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "\n",
        "    # calculate y_hat (final output with sigmoid function)\n",
        "    y_hat = 1 / (1 + np.exp(-z2))\n",
        "\n",
        "    return y_hat, z1, a1\n"
      ],
      "metadata": {
        "id": "SwGOAS0-GjNN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، یک تابع برای پس‌انتشار خطا پیاده‌سازی می‌کنیم. این تابع گرادیان‌های مورد نیاز برای به‌روزرسانی وزن‌ها و بایاس‌ها را محاسبه می‌کند.\n",
        "اینجا از فرمول‌هایی که قبلاً در تحقیق قبل بیان کردیم استفاده می‌شود\n"
      ],
      "metadata": {
        "id": "4u6zQjlgHtMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, y_hat, z1, a1, W2):\n",
        "    \"\"\"\n",
        "    Implement error backpropagation to compute gradients\n",
        "    X: input data\n",
        "    y: real labels\n",
        "    y_hat: predicted output\n",
        "    z1, a1: intermediate values ​​of the hidden layer\n",
        "    W2: Output layer weights\n",
        "    Returns: gradients W1, b1, W2, b2\n",
        "    \"\"\"\n",
        "    m = X.shape[0]  # Number of samples\n",
        "\n",
        "    # The derivative of the loss function with respect to the output of the network\n",
        "    dz2 = y_hat - y\n",
        "\n",
        "    # Compute the gradients of the output layer\n",
        "    dW2 = np.dot(a1.T, dz2) / m\n",
        "    db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "\n",
        "    # Derivative relative to the hidden layer\n",
        "    dz1 = np.dot(dz2, W2.T) * (1 - np.tanh(z1) ** 2)\n",
        "\n",
        "    # Compute the gradients of the hidden layer\n",
        "    dW1 = np.dot(X.T, dz1) / m\n",
        "    db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "\n",
        "    return dW1, db1, dW2, db2\n"
      ],
      "metadata": {
        "id": "7lKHPBOXIChJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "در این مرحله، تابعی برای به‌روزرسانی وزن‌ها و بایاس‌ها با استفاده از گرادیان‌ها و نزول گرادیان پیاده‌سازی می‌کنیم."
      ],
      "metadata": {
        "id": "arCgGbeZdYxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    \"\"\"\n",
        "    Update weights and biases using gradient descent\n",
        "    learning_rate: learning rate\n",
        "    \"\"\"\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "\n",
        "    return W1, b1, W2, b2\n"
      ],
      "metadata": {
        "id": "oBNt21nAdZ7R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "تابع پیش‌بینی با استفاده از عبور رو به جلو اجرا می‌شود تا خروجی شبکه برای ورودی جدید محاسبه شود.\n",
        "از تابع forward_pass برای محاسبه خروجی شبکه استفاده می‌کنیم.\n",
        "سپس خروجی‌ها (مقادیر سیگموید) را با 0.5 مقایسه می‌کنیم تا پیش‌بینی‌های نهایی (0 یا 1) به دست آید.\n",
        "\n"
      ],
      "metadata": {
        "id": "RyBDUC_bdwKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W1, b1, W2, b2):\n",
        "    \"\"\"\n",
        "    Predict output for input data X\n",
        "    Returns: expected output (0 or 1)\n",
        "    \"\"\"\n",
        "    y_hat, _, _ = forward_pass(X, W1, b1, W2, b2)\n",
        "    predictions = (y_hat > 0.5).astype(int)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "L12EaSbpd3R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cnUt_KNneIcr"
      }
    }
  ]
}